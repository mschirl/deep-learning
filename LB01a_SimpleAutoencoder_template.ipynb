{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LB01a.0 Simple Autoencoder (40%)\n",
    "\n",
    "\n",
    "The term Auto-Encoder (AE) refers to a neural network that is trained on a very specific task: to\n",
    "reconstruct the data that is sent into the network, the input $\\vec{x}$, as its output $\\vec{y} = \\vec{x}$. A machine learning (ML) model of this type always consists of two major building blocks: an encoder as well as a\n",
    "decoder. The algorithms used in typical AEs are exactly the same as those in Artificial Neural Networks (ANNs). AEs are therefore still function estimators of their inputs, and use gradient descent to adjust their neurons’ weights by calculating the loss function’s gradient. Since the task of copying does not require labelling, AEs are attributed to the unsupervised learning branch of ML and can be seen as some of the first models from the discipline of deep learning (DL) that were successfully trained.\n",
    "\n",
    "<img src=\"resources/LB01a_simple_autoencoder.png\"/>\n",
    "\n",
    "The architecture of an AE, shown in the figure above, can be split into the encoder, which is\n",
    "used to generate a code $\\vec{h}$ through some encoding function:\n",
    "\n",
    "<center>$\\large \\vec{h} = encode(\\vec{x})$</center>\n",
    "\n",
    "$\\vec{h}$ is also called representation, latent space or context vector in related literature. Using this code, the\n",
    "decoder tries to find a reconstruction $\\vec{y}$ that resembles $\\vec{x}$ by decoding with:\n",
    "\n",
    "<center>$\\large \\vec{y} = decode(\\vec{h})$</center>\n",
    "\n",
    "Typically, AEs are constrained in some way, making the copying task harder and, therefore, preventing an exact reconstruction of $\\vec{x}$. This behavior is intended, since it compels the neural network to find a way to prioritize certain parts of $\\vec{x}$ it deems most relevant for the reconstruction task. Thus, information needed in the reconstruction of $\\vec{x}$ is saved in $\\vec{h}$, while redundancy in the input data is stored in the trainable parameters of an AE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the packages needed for this lecture\n",
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.callbacks import Callback, EarlyStopping, TensorBoard\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import time\n",
    "\n",
    "from skimage.metrics import mean_squared_error\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the log folder for tensorboard (helps by visualizing training curves)\n",
    "logdir = \"logs/\"\n",
    "modeldir = \"models/\"\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "    \n",
    "if not os.path.exists(modeldir):\n",
    "    os.makedirs(modeldir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting a specified number of images: original vs. encoded vs. decoded\n",
    "def plot_encoded_img(imgs, encoded_img, rnd_idx, aspect_ratio=0.1, decoded_img= None, title= None):\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    if title is not None:\n",
    "        plt.suptitle(title, fontsize= 16)\n",
    "\n",
    "    for i, image_idx in enumerate(rnd_idx):\n",
    "        # plot original image (input, x)\n",
    "        ax = plt.subplot(3, num_images, i + 1)\n",
    "        plt.imshow(imgs[image_idx].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # plot encoded image (latent space, h)\n",
    "        ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "        plt.imshow(encoded_img[image_idx].reshape(-1, 1), aspect=aspect_ratio)\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        if decoded_img is not None:\n",
    "            # plot reconstructed image (output, y)\n",
    "            ax = plt.subplot(3, num_images, 2 * num_images + i + 1)\n",
    "            plt.imshow(decoded_img[image_idx].reshape(28, 28))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LB01a.1 Data preparation\n",
    "\n",
    "* Load the [MNIST](http://yann.lecun.com/exdb/mnist/) data using `mnist.load_data()`\n",
    "\n",
    "* Prepare the input images:\n",
    "    * Convert images to float32-datatype (`.astype()`)\n",
    "    * Scale images to the interval [0, 1]\n",
    "    * Images have a 28x28 pixel resolution, transform them to a 1-dimensional vector using `.reshape()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load the mnist image data (28x28px)\n",
    "(x_train, _), (x_test, _) = ...\n",
    "\n",
    "# TODO: normalize images within the interval [0,1]\n",
    "x_train = ...\n",
    "x_test = ...\n",
    "\n",
    "# TODO: flatten the 28x28 images into a 1d vector (784,1)\n",
    "x_train = ...\n",
    "x_test = ...\n",
    "\n",
    "# TODO: print new flattened shapes of x_train and x_test\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LB01a.2 Autoencoder definition\n",
    "\n",
    "* Define an autoencoder which has the dimensionality of the latent space of $d = 128$\n",
    "* Two dense layers (encoder, decoder) are needed\n",
    "* Hint: use a `ReLU` for the encoding layer and a `sigmoid` for the decoding layer's activation function.\n",
    "* Choose an appropriate optimizer and loss function for your task\n",
    "* Compute and output the compression factor of latent space versus input dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get dimensions for the AE's input layer\n",
    "input_dim = ...\n",
    "\n",
    "# TODO: define size of encoded representations , i.e. latent space\n",
    "encoding_dim = ...\n",
    "\n",
    "# TODO: compute compression factor, i.e. dimensionality reduction\n",
    "compression_factor = ...\n",
    "print('Compression factor: %.1f' % compression_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define the AE's architecture using the sequential model, give your model the name \"Simple_Autoencoder\"\n",
    "autoencoder = ...\n",
    "\n",
    "# TODO: add needed layers to your model\n",
    "...\n",
    "\n",
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the autoencoder with suited optimizer and loss function\n",
    "autoencoder.compile(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set the number of epochs to 50\n",
    "max_epochs= ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = TensorBoard(log_dir=logdir + \"AE_Simple_\" + datetime.now().strftime(\"%Y.%m.%d-%H:%M:%S\"))\n",
    "\n",
    "# TODO: train the autoencoder using input and target accordingly. Think about what we want an AE\n",
    "# TODO: to do. Also shuffle training data and provide a validation split. \n",
    "# TODO: Apply the tensorboard callback to the fit command\n",
    "# TODO: Set the number of epochs to max_epochs.\n",
    "# input = target\n",
    "autoencoder.fit(...)\n",
    "\n",
    "# TODO: save the entire model graph with weights to the following model path\n",
    "model_path = modeldir + 'autoencoder.h5'\n",
    "...\n",
    "\n",
    "del autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see the training curves you can now activate the tensorboard in your docker container using the following command after navigating to the working directory (e.g. `/notebooks/<your-working-directory>/`): \n",
    "\n",
    "`tensorboard --logdir logs --host 0.0.0.0`\n",
    "\n",
    "Please note that the `--logdir` parameter has to be the same as your `logdir` variable. \n",
    "\n",
    "Afterwards navigate to [http://localhost:6006](http://localhost:6006) in your internet browser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(modeldir + 'autoencoder.h5'):\n",
    "    print('No model file for autoencoder found.')\n",
    "    sys.exit(-1)\n",
    "    \n",
    "# load the entire model (no compilation necessary)\n",
    "autoencoder = load_model(modeldir + 'autoencoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LB01a.3 Evaluation\n",
    "\n",
    "* Extract the encoder layer of the autoencoder for the visualization\n",
    "* Use the autoencoder model to predict the test images\n",
    "* Compute the average mean squared error of all images in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: extract just the encoder part of the autoencoder to visualize the encoded representation (latent space)\n",
    "encoder_layer = ...\n",
    "\n",
    "# TODO: create a new sequential model containing only the encoder part\n",
    "encoder = ...\n",
    "encoder.add(...)\n",
    "\n",
    "print(encoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: encode the test images using just the encoder model\n",
    "encoded_imgs = ...\n",
    "# TODO: encode/decode the test images with the full autoencoder model\n",
    "decoded_imgs = ...\n",
    "\n",
    "# TODO: compute the average MSE over all test images (original/decoded)\n",
    "...\n",
    "\n",
    "avg_mse = ...\n",
    "print('Average MSE for all original/decoded images: %.4f' % avg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a random selection of images: original vs. encoded vs. decoded\n",
    "# just an example how to generate a random index in order to select original/encoded/decoded images from\n",
    "# the test set\n",
    "num_images = 20\n",
    "np.random.seed(42)\n",
    "random_images = np.random.randint(x_test.shape[0], size=num_images)\n",
    "plot_encoded_img(x_test, encoded_imgs, random_images, aspect_ratio=0.1, decoded_img= decoded_imgs, title='Simple Autoencoder - Original vs. Encoded vs. Decoded')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
