{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LB02.0 Convolutional Neural Networks (CNNs)\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are a special type of neural networks that are typically used to process multidimensional data. Especially when dealing with pictures or time series, CNNs may be your best choice. CNNs use convolutions within the network, hence the name. The operation is performed with a kernel that is moved across the grid-like data structures that are fed into the network.\n",
    "\n",
    "### Convolutions\n",
    "In general, convolutions may be described as an operation applied to two functions $f$ and $g$ that gives us a third function $f * g$. You can picture convolutions by considering a space ship that is moving through space while its position is tracked by a laser beam. The laser's output may be described by the function $x(t)$, where both $x$ and $t$ consist of real valued measurements. While these measurements may help you to track the aforementioned space ship on its way through the universe, you may also use convolutions to approximate the space ship's position. An approximation such as this may be more convenient in use than querying the laser's measuerment $x(t)$ over and over again every millisecond.\n",
    "\n",
    "If a weighting function $w(a)$, with $a$ describing the age of a measurement, is applied over time, it results in a function $s$, which gives us a way to aproximate a smoothed average position of the space ship.\n",
    "\n",
    "\\begin{equation}\n",
    "s(t) = \\int x(a)\\cdot w(t - a) da\n",
    "\\end{equation}\n",
    "\n",
    "This operation is referred to as convolution in literature and is typically denominated by a star-like symbol.\n",
    "\n",
    "\\begin{equation}\n",
    "s(t) = (x * w) (t).\n",
    "\\end{equation}\n",
    "\n",
    "When facing discrete values, as is typical when processing time values $t$ that are recorded periodically, a discrete convolution may be used:\n",
    "\n",
    "\\begin{equation}\\label{discrete_convolution}\n",
    "s(t) = (x * w)(t) = \\sum_{a=-\\infty}^{\\infty} x(a)\\cdot w(t - a).\n",
    "\\end{equation}\n",
    "\n",
    "In CNNs, the first argument of the function, $x$, is usually denoted as **input** whereas the second argument ($w$) is called **kernel**. As mentioned in the introduction, the input $x$ most commonly consists of multidimensional data while the kernel $w$ holds a multidimensional array of parameters that are to be optimized through machine learning.\n",
    "\n",
    "#### Convolutions in image processing\n",
    "In image processing, $\\boldsymbol{I}$ is usually used to describe the input image to a convolution, $\\boldsymbol{K}$ denotes the kernel and $\\boldsymbol{S}$ describes the output picture that results from the convolution.\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{S\\,}(i, j) = (\\boldsymbol{I} * \\boldsymbol{K\\,}) (i, j) = \\sum_{m} \\sum_{n} \\boldsymbol{I\\,}(m,n)\\cdot \\boldsymbol{K\\,}(i - m, j - n).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just to suppress some annoying warning messages\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "    # import h5py\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import __version__\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras import datasets\n",
    "from keras import callbacks\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the log folder for tensorboard (helps by visualizing training curves)\n",
    "logdir = \"cnn_logs/\"\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is needed later when evaluating the classifier's results.\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=2, out=None)  \n",
    "    \n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NumPy Version: %s' % np.__version__)\n",
    "print('Tensorflow Version: %s' % tf.__version__)\n",
    "print('Keras Version: %s\\n' % __version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LB02.1 Data preparation\n",
    "\n",
    "* Load the [MNIST](http://yann.lecun.com/exdb/mnist/) data using `mnist.load_data()`\n",
    "\n",
    "* Prepare the input images:\n",
    "    * Convert images to float32-datatype (`.astype()`)\n",
    "    * Scale images to the interval [0, 1]\n",
    "    * Reshape the data in order to get a 4th dimension. You will need a 4d tensor when using CNNs with Keras\n",
    "    * **Important**: Apply one hot encoding to the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load the mnist dataset, X_test is used for final performance evaluation only\n",
    "(X_train, y_train), (X_test, y_test) = ...\n",
    "\n",
    "# TODO: print the current dimensions of the dataset\n",
    "print(\"Training matrix shape\", ...)\n",
    "print(\"Testing matrix shape\", ...)\n",
    "print(\"Training labels shape\", ...)\n",
    "print(\"Testing labels shape\", ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: convert the train and test data to a floating number\n",
    "X_train = ...\n",
    "X_test = ...\n",
    "\n",
    "# TODO: normalize images within the interval [0,1]\n",
    "X_train /= ...\n",
    "X_test /= ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: reshape to add an additional dimension in order to create a needed tensor\n",
    "X_train= ...\n",
    "X_test= ...\n",
    "\n",
    "# TODO: print the new dimensions of the dataset\n",
    "print(\"Training matrix shape - dimension added\", ...)\n",
    "print(\"Testing matrix shape - dimension added\", ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: convert the training labels to one hot encoded vectors\n",
    "y_train = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for selection of just a subset (faster computation to check if everything runs ok)\n",
    "# X_train= X_train[0:1000,:]\n",
    "# X_test= X_test[0:200,:]\n",
    "\n",
    "# y_train= y_train[0:1000]\n",
    "# y_test= y_test[0:200]\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LB02.2 Architecture Definition \n",
    "\n",
    "Implement a CNN for a MNIST dataset classification according to the architecture shown in the picture below.\n",
    "\n",
    "<img src=\"resources/LB02_cnn_architecture.png\"/>\n",
    "\n",
    "* Train the CNN for 25 epochs and use Adam with default values as an optimizer\n",
    "* Use rectified linear units for all activations but the final output layer\n",
    "* Make sure to use a suiting activation in the output layer\n",
    "* Use a batch size of 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define the parameters for the training\n",
    "batch_size = ...\n",
    "max_epochs = ...\n",
    "patience = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a callback in order to enable tensorboard visualizations\n",
    "tb = callbacks.TensorBoard(log_dir=logdir + \"AE_Stacked_Stack2_\" + datetime.now().strftime(\"%Y.%m.%d-%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining an early stopping callback\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_accuracy', min_delta=1e-04, patience=patience, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define the cnn model architecture shown in the picture above\n",
    "model = Sequential()\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define the optimizer \n",
    "adam = ...\n",
    "\n",
    "# TODO: compile the created model\n",
    "model.compile(...)\n",
    "\n",
    "# print model structure\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nStarting training process...\\n')\n",
    "\n",
    "# TODO: train the created model using your training data\n",
    "# TODO: make sure to use the defined number of epochs and the defined batch size\n",
    "# TODO: also use a validation split of 70/30 and created callbacks\n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see the training curves you can now activate the tensorboard in your docker container using the following command after navigating to the working directory (e.g. `/notebooks/<your-working-directory>/`): \n",
    "\n",
    "`tensorboard --logdir cnn_logs --host 0.0.0.0`\n",
    "\n",
    "Please note that the `--logdir` parameter has to be the same as your `logdir` variable. \n",
    "\n",
    "Afterwards navigate to [http://localhost:6006](http://localhost:6006) in your internet browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LB02.3 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use your trained model to predict the data\n",
    "prediction= ...\n",
    "\n",
    "# TODO: you will have to revert the categorical labels to the numerical \n",
    "# TODO: labels in order to use the `confusion_matrix` function. Hint: `argmax`\n",
    "y_pred = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print the accuracy score\n",
    "acc  = ...\n",
    "print(\"Accuracy: %.4f\" % ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TODO: calculate the confusion matrix\n",
    "cm = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot the confusion matrix\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LB02.4 Experimenting with CNNs\n",
    "In this step you will change the architecture of your network slightly and examine how these changes affect the outcome.\n",
    "\n",
    "Describe and document the outcome you observe. To do this, you may screenshot tensorboard's training curves and paste those directly into this notebook with a fitting description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB02.4a Dropout\n",
    "\n",
    "Use the same architecture as in LB02.3 but add a dropout layer after each max-pooling layer and after the first fully connected layer. Use a dropout percentage of 25%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB02.4b Different number of feature maps\n",
    "Use 16 feature maps for Conv1 and 32 feature Maps for Conv2. \n",
    "How does this afffect the number of the trainable parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB02.4c Stride\n",
    "Use the same architecture as in LB02.3 but add a stride of 2 for Conv1. Observe the size of the feature maps and compare results to the architecture without stride.\n",
    "Describe, in your own words, how stride affects the feature map's dimensions in your CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB02.4d Increased number of trainable parameters\n",
    "Use 64 feature maps for Conv1 and 128 feature maps for Conv2 with 30% dropout.\n",
    "Increase the number of neurons of the first fully connected layer to 256.\n",
    "Observe the training progress and the model performance. Is this performance superior in comparison to previous results? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
