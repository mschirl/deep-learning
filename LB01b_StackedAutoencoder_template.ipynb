{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LB01b.0 Stacked Autoencoder (60%)\n",
    "\n",
    "The idea behind Stacked Autoencoders is to stack multiple simple autoencoders where output of each hidden layer is connected to the input of the successive autoencoder. \n",
    "\n",
    "<img src=\"resources/LB01b_stack1_stack2.png\"/>\n",
    "\n",
    "In the image above you can see Stack 1 and Stack 2. These are two simple autoencoders as we know them from the LB01a. As you can see, the latent space of the Stack 1 is used as the input for the Stack 2. \n",
    "\n",
    "\n",
    "<img src=\"resources/LB01b_stacked_autoencoder.png\"/>\n",
    "\n",
    "The stacking of the two autoencoders \"Stack 1\" and \"Stack 2\" will result in the architecture depicted in the image above.\n",
    "\n",
    "In order to train this model you will have to use two separate sequential models. The encoded output of the first layer will serve as input and training of the second layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the packages needed for this lecture\n",
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, InputLayer, Dense\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.callbacks import Callback, EarlyStopping, TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "import keras as K\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import time\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the log folder for tensorboard (helps by visualizing training curves)\n",
    "logdir = \"logs/\"\n",
    "modeldir = \"models/\"\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "    \n",
    "if not os.path.exists(modeldir):\n",
    "    os.makedirs(modeldir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting a specified number of images: original vs. encoded vs. decoded\n",
    "def plot_encoded_img(imgs, encoded_img, rnd_idx, aspect_ratio=0.1, decoded_img= None, title= None):\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    if title is not None:\n",
    "        plt.suptitle(title, fontsize= 16)\n",
    "\n",
    "    for i, image_idx in enumerate(rnd_idx):\n",
    "        # plot original image (input, x)\n",
    "        ax = plt.subplot(3, num_images, i + 1)\n",
    "        plt.imshow(imgs[image_idx].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # plot encoded image (latent space, h)\n",
    "        ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "        plt.imshow(encoded_img[image_idx].reshape(-1, 1), aspect=aspect_ratio)\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        if decoded_img is not None:\n",
    "            # plot reconstructed image (output, y)\n",
    "            ax = plt.subplot(3, num_images, 2 * num_images + i + 1)\n",
    "            plt.imshow(decoded_img[image_idx].reshape(28, 28))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is needed later when evaluating the classifier's results.\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=2, out=None)  \n",
    "    \n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LB01b.1 Data preparation\n",
    "\n",
    "* Load the [MNIST](http://yann.lecun.com/exdb/mnist/) data using `mnist.load_data()`\n",
    "\n",
    "* Prepare the input images:\n",
    "    * Convert images to float32-datatype (`.astype()`)\n",
    "    * Scale images to the interval [0, 1]\n",
    "    * Images have a 28x28 pixel resolution, transform them to a 1-dimensional vector using `.reshape()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load the mnist image data (28x28px) and its labels (can be used later on for SVM classification)\n",
    "(x_train, y_train), (x_test, y_test) = ...\n",
    "\n",
    "# TODO: normalize images within the interval [0,1]\n",
    "x_train = ...\n",
    "x_test = ...\n",
    "\n",
    "# TODO: flatten the 28x28 images into a 1d vector\n",
    "x_train = ...\n",
    "x_test = ...\n",
    "\n",
    "# TODO: print new flattened shapes of x_train and x_test\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LB01b.2 Stacked Autoencoder definition\n",
    "\n",
    "Using the knowledge gathered in the exercise LB01a implement a stacked autoencoder with two hidden layers with the dimensionality of $d_1 = 128$ and $d_2 = 32$\n",
    "\n",
    "* Each stack has to be trained separately. Hence, two separate sequential models are needed.\n",
    "* Hint: Use sigmoid activation function for all layers.\n",
    "* The encoded output of the first layer serves as input of the second layer. \n",
    "* The encoded output of the second layer represents the latent space. \n",
    "* Extract the weights (`get_weights()`) of all layers in order to create the final model at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get dimensions for the AE's input layer\n",
    "input_dim = ...\n",
    "\n",
    "# TODO: define size of encoded representations for the 2 stacks\n",
    "encoding_dim1 = ...\n",
    "encoding_dim2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute compression factor, i.e. dimensionality reduction\n",
    "compression_factor = ...\n",
    "print('Compression factor: %.1f' % compression_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define autoencoder stack 1\n",
    "autoencoder1= ...\n",
    "autoencoder1.add(...)\n",
    "autoencoder1.add(...)\n",
    "\n",
    "# TODO: define autoencoder stack 2\n",
    "autoencoder2= ...\n",
    "autoencoder2.add(...)\n",
    "autoencoder2.add(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the architectures of the two stacks of the autoencoder\n",
    "print(autoencoder1.summary())\n",
    "print(autoencoder2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compile your first autoencoder\n",
    "autoencoder1.compile(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set the number of epochs to 50\n",
    "max_epochs= ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = TensorBoard(log_dir=logdir + \"AE_Stacked_Stack1_\" + datetime.now().strftime(\"%Y.%m.%d-%H:%M:%S\"))\n",
    "\n",
    "# TODO: train the autoencoder using input and target accordingly. Think about what we want an AE\n",
    "# TODO: to do. Also shuffle training data and provide a validation split. \n",
    "# TODO: Apply the tensorboard callback to the fit command\n",
    "# TODO: Set the number of epochs to max_epochs.\n",
    "# input = target\n",
    "autoencoder1.fit(...)\n",
    "\n",
    "# TODO: save the entire model graph with weights to the following model path\n",
    "model_path = modeldir + 'stack1.h5'\n",
    "...\n",
    "\n",
    "del(autoencoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see the training curves you can now activate the tensorboard in your docker container using the following command after navigating to the working directory (e.g. `/notebooks/<your-working-directory>/`): \n",
    "\n",
    "`tensorboard --logdir logs --host 0.0.0.0`\n",
    "\n",
    "Please note that the `--logdir` parameter has to be the same as your `logdir` variable. \n",
    "\n",
    "Afterwards navigate to [http://localhost:6006](http://localhost:6006) in your internet browser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the entire model (no compilation necessary)\n",
    "autoencoder1 = load_model(modeldir + \"stack1.h5\")\n",
    "\n",
    "# TODO: extract the encoder part of the first autoencoder\n",
    "stack1_encoder = ...\n",
    "\n",
    "# TODO: Create a new sequential model with only the encoder part of \n",
    "# TODO: the autoencoder. You will use this model to generate input for the \n",
    "# TODO: successive autoencoder (Stack 2).\n",
    "encoder1= ...\n",
    "\n",
    "# printing the summary and deleting the first autoencoder from memory\n",
    "print(encoder1.summary())\n",
    "del(autoencoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: now use the encoder part of the first autoencoder \n",
    "# TODO: to generate latent representations\n",
    "encoded1_imgs = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: now go on with the second autoencoder, compile the model you created\n",
    "# TODO: use a suited optimizer and loss function\n",
    "autoencoder2.compile(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = TensorBoard(log_dir=logdir + \"AE_Stacked_Stack2_\" + datetime.now().strftime(\"%Y.%m.%d-%H:%M:%S\"))\n",
    "\n",
    "# TODO: Train the second autoencoder using input and target accordingly. \n",
    "# TODO: Remember to use the output of the first encoder as input for this one.\n",
    "# TODO: Also shuffle training data and provide a validation split. \n",
    "# TODO: Apply the tensorboard callback to the fit command\n",
    "# TODO: Set the number of epochs to max_epochs.\n",
    "# input = target\n",
    "autoencoder2.fit(...)\n",
    "\n",
    "# TODO: save the entire model graph with weights to the following model path\n",
    "model_path = modeldir + 'stack2.h5'\n",
    "...\n",
    "\n",
    "del(autoencoder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder2 = load_model(modeldir + \"stack2.h5\")\n",
    "\n",
    "# TODO: Extract just the second encoder to visualize the encoded representation\n",
    "# TODO: (latent space), also can serve as feature extractor (or dimensionality reduction)\n",
    "stack2_encoder = ...\n",
    "\n",
    "# TODO: Create a new sequential model with only the encoder part of \n",
    "# TODO: the second autoencoder. You will use this model to generate \n",
    "# TODO: the encoded representations.\n",
    "encoder2 = ...\n",
    "\n",
    "# printing the summary \n",
    "print(encoder2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Encode the images encoded by autoencoder stack 1, with autoencoder stack 2. \n",
    "# TODO: The result are the images in latent space\n",
    "encoded2_imgs = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Now lets get ready to build the whole model #####\n",
    "# TODO: Load the stack 1 and stack 2 from your hard drive.\n",
    "autoencoder1 = ...\n",
    "autoencoder2 = ...\n",
    "\n",
    "# TODO: Create a new sequential model \n",
    "stacked_autoencoder = ...\n",
    "# TODO: Add the layers of the stack 1 and stack 2 accordingly to your new model\n",
    "...\n",
    "\n",
    "# TODO: Compile the newly created model\n",
    "stacked_autoencoder.compile(...)\n",
    "\n",
    "# printing the summary\n",
    "print(stacked_autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the new stacked autoencoder is created, we will have to \n",
    "# reuse the weights of the stack 1 and stack 2 and set them accordingly to the\n",
    "# layers of the new model.\n",
    "\n",
    "# TODO: Extract the weights of the encoder and decoder parts of both stacks\n",
    "stack1_enc_weights = ...\n",
    "stack1_dec_weights = ...\n",
    "stack2_enc_weights = ...\n",
    "stack2_dec_weights = ...\n",
    "\n",
    "# TODO: set the extracted weigths to the matching layers of the stacked autoencoder\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a new sequential model, which will only contain the encoder\n",
    "# TODO: part of the stacked autoencoder.\n",
    "stacked_encoder = Sequential(name= \"Stacked_Encoder\")\n",
    "stacked_encoder.add(...)\n",
    "stacked_encoder.add(...)\n",
    "\n",
    "# TODO: compile your new encoder model\n",
    "stacked_encoder.compile(...)\n",
    "\n",
    "# printing the summary\n",
    "print(stacked_encoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the encoder is created, we will have to \n",
    "# reuse the weights of the autoencoder and set them accordingly to the\n",
    "# layers of the new encoder.\n",
    "\n",
    "# TODO: Reuse the extracted weights of the encoder parts of the \n",
    "# TODO: stacked autoencoder and set them to the new encoder.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LB01b.3 Evaluation\n",
    "\n",
    "* Use the encoder part of the autoencoder in order to create the latent space predictions\n",
    "* Use your stacked autoencoder in order to predict the test images\n",
    "* Compute the average mean squared error of all images in the test set\n",
    "* Use a simple MLP to classify the data based on the generated features\n",
    "* Use a support vector machine to classify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the encoder part of the stacked autoencoder in order to generate\n",
    "# TODO: representations of the latent space.\n",
    "encoded_imgs = ...\n",
    "\n",
    "# TODO: Encode/decode the test images with the full stacked autoencoder model.\n",
    "decoded_imgs = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the average MSE over all test images (original/decoded)\n",
    "...\n",
    "\n",
    "avg_mse= ...\n",
    "print('Average MSE for all original/decoded images: %.4f' % avg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a random selection of images: original vs. encoded vs. decoded\n",
    "# just an example how to generate a random index in order to select original/encoded/decoded images from\n",
    "# the test set\n",
    "num_images = 20\n",
    "np.random.seed(42)\n",
    "random_images = np.random.randint(x_test.shape[0], size=num_images)\n",
    "plot_encoded_img(x_test, encoded_imgs, random_images, aspect_ratio=0.1, decoded_img= decoded_imgs, title='Deep Autoencoder - Reconstructed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Now lets use the generated representations and try to classify #####\n",
    "#### the input data based on the representations.                   #####\n",
    "\n",
    "# TODO: Create a sequential model\n",
    "classification_mlp = ...\n",
    "# TODO: Add a dense layer with 16 nodes and use relu as activation function\n",
    "classification_mlp.add(...)\n",
    "# TODO: Add the classification layer. Recall the knowledge from last semester:\n",
    "# TODO:     - How many nodes do you need?\n",
    "# TODO:     - Which activation function do you need?\n",
    "classification_mlp.add(...)\n",
    "\n",
    "# TODO: Compile the model with a suited optimizer and loss function\n",
    "classification_mlp.compile(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# TODO: Use the suited function to generate categorical labels for your dataset\n",
    "y_train_categorical = ...\n",
    "y_test_categorical = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the encoder part of the stacked autoencoder to generate the representations \n",
    "# TODO: for the train and test data\n",
    "x_train_features = stacked_encoder.predict(...)\n",
    "x_test_features = stacked_encoder.predict(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = TensorBoard(log_dir=logdir + \"MLP_\" + datetime.now().strftime(\"%Y.%m.%d-%H:%M:%S\"))\n",
    "\n",
    "# TODO: Fit your newly created MLP, use 100 epochs and batch size of 256.\n",
    "# TODO: Also shuffle your data and use a validation split of 70/30.\n",
    "classification_mlp.fit(....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the fitted classificator and predict the data.\n",
    "y_pred = classification_mlp.predict(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import argmax\n",
    "\n",
    "# TODO: You will have to revert the categorical labels to the numerical \n",
    "# TODO: labels in order to use the `confusion_matrix` function. Hint: `argmax`\n",
    "y_pred = ...\n",
    "cm = confusion_matrix(...)\n",
    "\n",
    "# TODO: Print the accuracy score\n",
    "acc_score = ...\n",
    "print('Accuracy: %.4f' % acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the confusion matrix\n",
    "plot_confusion_matrix(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Now lets try another classifier. #####\n",
    "\n",
    "# TODO: Create a support vector machine classifier using sklearns SVC \n",
    "# TODO: (Hint: `sklearn.svm.SVC`)\n",
    "clf= ...\n",
    "\n",
    "# TODO: Fit your newly created classifier\n",
    "clf.fit(...)\n",
    "\n",
    "# TODO: Predict the test data.\n",
    "y_pred= clf.predict(...)\n",
    "\n",
    "# TODO: Print the accuracy score\n",
    "acc_score = ...\n",
    "print('Accuracy: %.4f' % acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute the confusion matrix.\n",
    "cm = confusion_matrix(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the confusion matrix.\n",
    "plot_confusion_matrix(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
